# ğŸš€ Projet 4 â€” *Classifiez automatiquement des informations*  
### _(Formation IngÃ©nieur Intelligence Artificielle â€“ Projet HR Analytics)_

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=Python)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-orange?logo=pandas)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-green?logo=scikitlearn)
![SHAP](https://img.shields.io/badge/Explainability-SHAP-purple)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)
![Category](https://img.shields.io/badge/Category-HR%20Analytics-grey)

---

## ğŸ“Œ RÃ©sumÃ© Professionnel du Projet

Ce projet sâ€™inscrit dans un cas rÃ©el dâ€™**analyse RH** au sein de lâ€™ESN *TechNova Partners*, confrontÃ©e Ã  une hausse significative de son **taux dâ€™attrition**.  
En tant que **Consultant Data Scientist**, lâ€™objectif est dâ€™identifier les *causes racines des dÃ©missions* et de dÃ©velopper un **modÃ¨le de classification** prÃ©dictif du risque de dÃ©part.

Lâ€™analyse repose sur trois sources principales de donnÃ©es fournies par le dÃ©partement SIRH :

- **Extrait du SIRH** : Ã¢ge, fonction, anciennetÃ©, salaire, donnÃ©es sociodÃ©mographiques.
- **Ã‰valuations annuelles** : notes de performance, feedback, satisfaction.
- **Sondage interne** : perception du bien-Ãªtre, environnement de travail, intention de dÃ©part.

Le travail comprend :  
ğŸ” *Analyse exploratoire* â€“ ğŸ§¹ *PrÃ©paration de la donnÃ©e* â€“ ğŸ¤– *ModÃ©lisation* â€“ ğŸš€ *Optimisation* â€“ ğŸ§  *InterprÃ©tation SHAP*.  
Lâ€™objectif final : fournir aux RH une **vision objective, chiffrÃ©e et actionnable** sur les facteurs expliquant les dÃ©parts.

---

# ğŸ“‚ Structure du Projet

## ğŸ”§ Ã‰tape prÃ©alable â€” PrÃ©parez lâ€™environnement de travail
- Mise en place de lâ€™environnement Python (Pandas, Scikit-Learn, SHAP).
- Import des trois fichiers sources.
- VÃ©rification de lâ€™intÃ©gritÃ© des colonnes et formats.
- Mise en place du versionnement Git/GitHub.

---

## ğŸ” Ã‰tape 1 â€” Analyse exploratoire des fichiers de donnÃ©es
- Comparaison employÃ©s *actifs* vs *dÃ©missionnaires*.
- Analyse univariÃ©e & multivariÃ©e :
  - salaire, anciennetÃ©, notes de satisfaction, charge de travail.
- Recherche de patterns discriminants :
  - anomalies, valeurs extrÃªmes, variables Ã  forte corrÃ©lation.
- Visualisations pour formuler les premiÃ¨res hypothÃ¨ses de causes dâ€™attrition.

---

## ğŸ§¹ Ã‰tape 2 â€” PrÃ©paration de la donnÃ©e pour la modÃ©lisation
- Fusion des sources via un ID unique.
- Nettoyage des valeurs manquantes et harmonisation des formats.
- Encodage des variables catÃ©gorielles.
- Standardisation / normalisation selon les modÃ¨les.
- Gestion du dÃ©sÃ©quilibre de classes : `class_weight` ou SMOTE.
- CrÃ©ation dâ€™un dataset final prÃªt pour la modÃ©lisation.

---

## ğŸ¤– Ã‰tape 3 â€” RÃ©alisation dâ€™un premier modÃ¨le de classification
- Split Train/Test (stratifiÃ©).
- Baseline via `DummyClassifier` pour mesurer le gain rÃ©el.
- Premiers modÃ¨les :
  - RÃ©gression Logistique  
  - Random Forest  
  - XGBoost
- Ã‰valuation selon :
  - Accuracy  
  - Recall  
  - F1-score  
  - AUC ROC

---

## ğŸš€ Ã‰tape 4 â€” AmÃ©lioration de lâ€™approche de classification
- Optimisation des hyperparamÃ¨tres : GridSearch / RandomizedSearch.
- Comparaison de plusieurs pipelines.
- SÃ©lection dâ€™attributs importants (feature selection).
- RÃ©duction du sur-apprentissage + stabilisation des performances.

---

## ğŸ§  Ã‰tape 5 â€” Optimisation et interprÃ©tation du modÃ¨le (SHAP)
- Feature importance **globale** :
  - Satisfaction  
  - Note de performance  
  - AnciennetÃ©  
  - Salaire  
  - Charge de travail  
- Analyse **locale** via waterfall plots pour expliquer chaque prÃ©diction.  
- Identification de **leviers RH actionnables** :
  - AmÃ©lioration du management  
  - Ajustements sur la charge de travail  
  - Programmes de reconnaissance  
  - Actions sur les salaires / promotions

---

# ğŸ§­ Roadmap â€” AmÃ©liorations Futures & TODO

### ğŸ”„ ModÃ¨le & Performance
- [ ] IntÃ©grer LightGBM et CatBoost pour comparaison.  
- [ ] Ajouter un modÃ¨le de stacking pour amÃ©liorer lâ€™AUC.  
- [ ] Mettre en place une calibration des probabilitÃ©s (Platt / Isotonic).

### ğŸ“Š Analyse & Reporting
- [ ] Ajouter un rapport automatique (ydata-profiling / Sweetviz).  
- [ ] CrÃ©er un dashboard RH interactif (Streamlit / Dash).  
- [ ] Ajouter une analyse temporelle si lâ€™historique est disponible.

### ğŸ§± Pipeline & QualitÃ©
- [ ] Industrialiser lâ€™ensemble via `Pipeline()` + `ColumnTransformer`.  
- [ ] Ajouter des tests unitaires (PyTest) pour le preprocessing.  
- [ ] Traquer les expÃ©riences et les modÃ¨les via MLflow.

### ğŸ§© Exploitation RH
- [ ] Construire une matrice â€œFacteur â†’ Action recommandÃ©eâ€.  
- [ ] DÃ©finir des personas dâ€™employÃ©s Ã  risque.  
- [ ] Automatiser un scoring mensuel des collaborateurs.

---

# ğŸ“ DonnÃ©es utilisÃ©es
- `Extrait_SIRH.csv`  
- `Evaluations_performance.csv`  
- `Sondage_employes.csv`

---

Projet rÃ©alisÃ© dans le cadre du parcours **IngÃ©nieur en Intelligence Artificielle** â€“ Mission HR Analytics (Projet 4).

---

**Auteur :** *[Raymond Francius]*   
**RÃ´le :** *[Apprenant - Promotion Sept-2025]* â€” **Engineer AI** â€” **Openclassrooms**    
**Date de mise Ã  jour :** *[04-11-2025]*   
**Client fictif :** *TechNova Partners*      
**Projet :** Projet4 â€” Mission HR Analytics  
